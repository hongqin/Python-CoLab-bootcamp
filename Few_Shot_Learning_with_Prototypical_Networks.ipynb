{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hongqin/Python-CoLab-bootcamp/blob/master/Few_Shot_Learning_with_Prototypical_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9712fd64",
      "metadata": {
        "id": "9712fd64"
      },
      "source": [
        "# Few-Shot Learning with Prototypical Networks on Omniglot Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "438fb9c2",
      "metadata": {
        "id": "438fb9c2"
      },
      "source": [
        "## Step 1: Import Libraries and Prepare Data\n",
        "In this step, we will import the necessary libraries and prepare the Omniglot dataset for our few-shot learning task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c512a071",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c512a071",
        "outputId": "bedebb29-0d97-452e-d26a-af3269d90955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_background.zip to ./data/omniglot-py/images_background.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9464212/9464212 [00:00<00:00, 74254768.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/omniglot-py/images_background.zip to ./data/omniglot-py\n",
            "Downloading https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_evaluation.zip to ./data/omniglot-py/images_evaluation.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6462886/6462886 [00:00<00:00, 74539228.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/omniglot-py/images_evaluation.zip to ./data/omniglot-py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "# Ensure reproducibility\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "\n",
        "# Transformations for the Omniglot dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "# Load Omniglot dataset\n",
        "train_dataset = datasets.Omniglot(root='./data', background=True, download=True, transform=transform)\n",
        "test_dataset = datasets.Omniglot(root='./data', background=False, download=True, transform=transform)\n",
        "\n",
        "# Extract characters and their classes\n",
        "train_characters = defaultdict(list)\n",
        "test_characters = defaultdict(list)\n",
        "\n",
        "for idx, (image, target) in enumerate(train_dataset):\n",
        "    train_characters[target].append(idx)\n",
        "\n",
        "for idx, (image, target) in enumerate(test_dataset):\n",
        "    test_characters[target].append(idx)\n",
        "\n",
        "train_classes = list(train_characters.keys())\n",
        "test_classes = list(test_characters.keys())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2c06f72",
      "metadata": {
        "id": "e2c06f72"
      },
      "source": [
        "## Step 2: Define the Prototypical Network\n",
        "Here, we define the Prototypical Network model, which consists of a simple convolutional neural network (CNN) used for embedding the input images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "386db671",
      "metadata": {
        "id": "386db671"
      },
      "outputs": [],
      "source": [
        "\n",
        "class PrototypicalNetwork(nn.Module):\n",
        "    def __init__(self, input_channels, hidden_dim, output_dim):\n",
        "        super(PrototypicalNetwork, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, hidden_dim, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(hidden_dim, output_dim, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(output_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d(1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        return x.view(x.size(0), -1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb7733e5",
      "metadata": {
        "id": "fb7733e5"
      },
      "source": [
        "## Step 3: Helper Functions for Few-Shot Learning\n",
        "We create helper functions to generate few-shot learning episodes and to compute Euclidean distances between embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "aa434df3",
      "metadata": {
        "id": "aa434df3"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_episode(dataset, characters, num_classes, num_support, num_query):\n",
        "    selected_classes = random.sample(characters.keys(), num_classes)\n",
        "    support_x = []\n",
        "    query_x = []\n",
        "    support_y = []\n",
        "    query_y = []\n",
        "\n",
        "    for i, cls in enumerate(selected_classes):\n",
        "        indices = characters[cls]\n",
        "        support_indices = random.sample(indices, num_support)\n",
        "        query_indices = random.sample(list(set(indices) - set(support_indices)), num_query)\n",
        "\n",
        "        support_x.append(torch.stack([dataset[idx][0] for idx in support_indices]))\n",
        "        query_x.append(torch.stack([dataset[idx][0] for idx in query_indices]))\n",
        "        support_y.append(torch.ones(num_support) * i)\n",
        "        query_y.append(torch.ones(num_query) * i)\n",
        "\n",
        "    return (torch.cat(support_x), torch.cat(support_y)), (torch.cat(query_x), torch.cat(query_y))\n",
        "\n",
        "def euclidean_distance(x, y):\n",
        "    return torch.sqrt(torch.sum((x - y) ** 2, dim=-1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "382afeee",
      "metadata": {
        "id": "382afeee"
      },
      "source": [
        "## Step 4: Train the Model\n",
        "We define a function to train the Prototypical Network using the few-shot learning episodes generated in the previous step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "204a7e33",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "204a7e33",
        "outputId": "fb836878-d1b4-49a4-b620-f50b9b5b6a80"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-e2774479de12>:2: DeprecationWarning: Sampling from a set deprecated\n",
            "since Python 3.9 and will be removed in a subsequent version.\n",
            "  selected_classes = random.sample(characters.keys(), num_classes)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode [100/1000], Loss: 1.6305\n",
            "Episode [200/1000], Loss: 1.6172\n",
            "Episode [300/1000], Loss: 1.6211\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def train_protonet(model, optimizer, train_dataset, train_characters, num_classes, num_support, num_query, num_episodes):\n",
        "    model.train()\n",
        "    for episode in range(num_episodes):\n",
        "        (support_x, support_y), (query_x, query_y) = create_episode(train_dataset, train_characters, num_classes, num_support, num_query)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        support_embeddings = model(support_x)\n",
        "        query_embeddings = model(query_x)\n",
        "\n",
        "        prototypes = []\n",
        "        for i in range(num_classes):\n",
        "            prototypes.append(support_embeddings[support_y == i].mean(dim=0))\n",
        "        prototypes = torch.stack(prototypes)\n",
        "\n",
        "        distances = torch.stack([euclidean_distance(query_embeddings, prototype) for prototype in prototypes])\n",
        "        predictions = torch.argmin(distances, dim=0)\n",
        "\n",
        "        loss = nn.CrossEntropyLoss()(distances.T, query_y.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (episode + 1) % 100 == 0:\n",
        "            print(f'Episode [{episode + 1}/{num_episodes}], Loss: {loss.item():.4f}')\n",
        "\n",
        "input_channels = 1\n",
        "hidden_dim = 64\n",
        "output_dim = 64\n",
        "num_classes = 5\n",
        "num_support = 5\n",
        "num_query = 15\n",
        "num_episodes = 1000\n",
        "\n",
        "model = PrototypicalNetwork(input_channels, hidden_dim, output_dim)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "train_protonet(model, optimizer, train_dataset, train_characters, num_classes, num_support, num_query, num_episodes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b74cc57b",
      "metadata": {
        "id": "b74cc57b"
      },
      "source": [
        "## Step 5: Evaluate the Model\n",
        "Finally, we evaluate the trained Prototypical Network on the test dataset to see how well it performs on few-shot learning tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f64b0de",
      "metadata": {
        "id": "6f64b0de"
      },
      "outputs": [],
      "source": [
        "\n",
        "def evaluate_protonet(model, test_dataset, test_characters, num_classes, num_support, num_query, num_episodes):\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(num_episodes):\n",
        "            (support_x, support_y), (query_x, query_y) = create_episode(test_dataset, test_characters, num_classes, num_support, num_query)\n",
        "\n",
        "            support_embeddings = model(support_x)\n",
        "            query_embeddings = model(query_x)\n",
        "\n",
        "            prototypes = []\n",
        "            for i in range(num_classes):\n",
        "                prototypes.append(support_embeddings[support_y == i].mean(dim=0))\n",
        "            prototypes = torch.stack(prototypes)\n",
        "\n",
        "            distances = torch.stack([euclidean_distance(query_embeddings, prototype) for prototype in prototypes])\n",
        "            predictions = torch.argmin(distances, dim=0)\n",
        "\n",
        "            total_correct += (predictions == query_y).sum().item()\n",
        "            total_samples += len(query_y)\n",
        "\n",
        "    accuracy = total_correct / total_samples\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "evaluate_protonet(model, test_dataset, test_characters, num_classes, num_support, num_query, num_episodes=100)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
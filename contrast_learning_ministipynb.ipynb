{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwBxD2gcOSqLJGCdICtr5o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hongqin/Python-CoLab-bootcamp/blob/master/contrast_learning_ministipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASztqzkXNfFj",
        "outputId": "2d3f1c5b-1ec2-4d81-b427-e70b290b7dc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 28477333.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 3906720.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 11589280.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3018144.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 2.3663\n"
          ]
        }
      ],
      "source": [
        "# generated by perplexity\n",
        "\n",
        "# Contrastive Learning Tutorial for Beginners\n",
        "# This tutorial demonstrates a basic implementation of contrastive learning using the MNIST dataset.\n",
        "\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set up data transformations\n",
        "# We convert the images to tensors and normalize them\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize with MNIST mean and std\n",
        "])\n",
        "\n",
        "# Load the MNIST dataset\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Define the neural network architecture\n",
        "class ContrastiveNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ContrastiveNet, self).__init__()\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)  # 1 input channel, 32 output channels, 3x3 kernel, stride 1\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)  # 32 input channels, 64 output channels, 3x3 kernel, stride 1\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(9216, 128)  # 9216 input features, 128 output features\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply convolutions with ReLU activation\n",
        "        x = nn.functional.relu(self.conv1(x))\n",
        "        x = nn.functional.relu(self.conv2(x))\n",
        "        # Apply max pooling\n",
        "        x = nn.functional.max_pool2d(x, 2)\n",
        "        # Flatten the tensor\n",
        "        x = torch.flatten(x, 1)\n",
        "        # Apply fully connected layer\n",
        "        x = self.fc(x)\n",
        "        # Normalize the output\n",
        "        return nn.functional.normalize(x, dim=1)\n",
        "\n",
        "# Create an instance of the model\n",
        "model = ContrastiveNet()\n",
        "\n",
        "# Define the contrastive loss function\n",
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self, temperature=0.5):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def forward(self, features):\n",
        "        batch_size = features.shape[0]\n",
        "        # Create labels for the positive pairs\n",
        "        labels = torch.arange(batch_size).to(features.device)\n",
        "\n",
        "        # Compute similarity matrix\n",
        "        similarity_matrix = torch.matmul(features, features.T)\n",
        "\n",
        "        # Create a mask to identify positive pairs\n",
        "        mask = torch.eye(batch_size, dtype=torch.bool).to(features.device)\n",
        "\n",
        "        # Extract positive and negative pairs\n",
        "        positives = similarity_matrix[mask].view(batch_size, -1)\n",
        "        negatives = similarity_matrix[~mask].view(batch_size, -1)\n",
        "\n",
        "        # Concatenate positive and negative similarities\n",
        "        logits = torch.cat([positives, negatives], dim=1)\n",
        "\n",
        "        # Create labels for the contrastive loss\n",
        "        labels = torch.zeros(batch_size, dtype=torch.long).to(features.device)\n",
        "\n",
        "        # Compute the contrastive loss\n",
        "        loss = nn.functional.cross_entropy(logits / self.temperature, labels)\n",
        "        return loss\n",
        "\n",
        "# Create instances of the loss function and optimizer\n",
        "criterion = ContrastiveLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Define the training function\n",
        "def train(model, train_loader, criterion, optimizer, epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for batch_idx, (data, _) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()  # Reset gradients\n",
        "            features = model(data)  # Forward pass\n",
        "            loss = criterion(features)  # Compute loss\n",
        "            loss.backward()  # Backward pass\n",
        "            optimizer.step()  # Update weights\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Print the average loss for the epoch\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}')\n",
        "\n",
        "# Train the model\n",
        "train(model, train_loader, criterion, optimizer)\n",
        "\n",
        "# Function to visualize the learned embeddings\n",
        "def visualize_embeddings(model, dataset, num_samples=1000):\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "    labels = []\n",
        "\n",
        "    # Generate embeddings for a subset of the dataset\n",
        "    with torch.no_grad():\n",
        "        for i in range(num_samples):\n",
        "            img, label = dataset[i]\n",
        "            embedding = model(img.unsqueeze(0))\n",
        "            embeddings.append(embedding.squeeze().numpy())\n",
        "            labels.append(label)\n",
        "\n",
        "    embeddings = torch.tensor(embeddings)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    # Plot the embeddings\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    for i in range(10):\n",
        "        idx = labels == i\n",
        "        plt.scatter(embeddings[idx, 0], embeddings[idx, 1], label=str(i))\n",
        "    plt.legend()\n",
        "    plt.title('2D Visualization of Learned Representations')\n",
        "    plt.show()\n",
        "\n",
        "# Visualize the embeddings\n",
        "visualize_embeddings(model, train_dataset)\n",
        "\n",
        "# Explanation of the Contrastive Learning process:\n",
        "# 1. We define a neural network that learns to map images to a 128-dimensional embedding space.\n",
        "# 2. The contrastive loss encourages similar images (same digit) to have similar embeddings,\n",
        "#    and different images (different digits) to have dissimilar embeddings.\n",
        "# 3. During training, we compute the similarity between all pairs of images in a batch.\n",
        "# 4. The loss function tries to maximize the similarity of positive pairs (same digit)\n",
        "#    while minimizing the similarity of negative pairs (different digits).\n",
        "# 5. After training, we visualize the learned embeddings to see how well the model\n",
        "#    has separated different digits in the embedding space.\n",
        "\n",
        "# This tutorial provides a basic introduction to contrastive learning.\n",
        "# In practice, more advanced techniques like data augmentation, larger models,\n",
        "# and more sophisticated loss functions are often used to achieve better results."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mlfw5jVCNf0-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}